{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack DPA Contest v2 with CPA and DPA\n",
    "\n",
    "In this guide, we will show how to attack the DPA V2 trace set with CPA and DPA method, with the help of the `scared` library.\n",
    "\n",
    "## The DPA V2 trace set\n",
    "\n",
    "For this example, we will use the [DPA Contest v2](http://www.dpacontest.org/v2/download.php). In the second version, they provide different sets of power measurement traces acquired from the [SASEBO-GII](http://satoh.cs.uec.ac.jp/SASEBO/en/board/sasebo-g2.html) platform performing AES-128 encryptions.\n",
    "\n",
    "In particular, you must download the raw traces of the public database DPA_contest2_public_base_diff_vcc_a128_2009_12_23.tar.bz2 archive.\n",
    "\n",
    "### Download and extract traces data\n",
    "\n",
    "If you want to download them, execute the following command lines. <br />\n",
    "⚠ **Warning:** **3.5**GB split in 4 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "!wget -O dpa_v2.tar.bz2.part0 http://www.dpacontest.org/v2/data/traces/DPA_contest2_public_base_diff_vcc_a128_2009_12_23.tar.bz2.part0\n",
    "!wget -O dpa_v2.tar.bz2.part1 http://www.dpacontest.org/v2/data/traces/DPA_contest2_public_base_diff_vcc_a128_2009_12_23.tar.bz2.part1\n",
    "!wget -O dpa_v2.tar.bz2.part2 http://www.dpacontest.org/v2/data/traces/DPA_contest2_public_base_diff_vcc_a128_2009_12_23.tar.bz2.part2\n",
    "!wget -O dpa_v2.tar.bz2.part3 http://www.dpacontest.org/v2/data/traces/DPA_contest2_public_base_diff_vcc_a128_2009_12_23.tar.bz2.part3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once downloaded, the 4 archive parts must be merged as follow:\n",
    "\n",
    "```python\n",
    "# Merge archive parts\n",
    "!cat dpa_v2.tar.bz2.part{0..3} > dpa_v2.tar.bz2\n",
    "```\n",
    "\n",
    "We can then extract the archive:\n",
    "\n",
    "```python\n",
    "!tar -xjf dpa_v2.tar.bz2\n",
    "```\n",
    "\n",
    "The extraction process can take long.\n",
    "The traces will be extracted into the `DPA_contest2_public_base_diff_vcc_a128_2009_12_23` directory (created during extraction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert traces\n",
    "\n",
    "After extracting the archive of the public base, we obtained 640,000 '.csv' traces files that correspond to 32 subsets of 20,000 traces.\n",
    "What changes among those 32 subsets are the key used for encryption.\n",
    "For each trace, a random plaintext was generated for encryption.\n",
    "\n",
    "Here is the kind of file we have:\n",
    "\n",
    "`./DPA_contest2_public_base_diff_vcc_a128_2009_12_23/wave_aist-aes-agilent_2009-12-31_01-33-21_n=29479_k=13198a2e03707344a4093822299f31d0_m=8d4207d890f562309724374abde6e569_c=1ed272974f92997d97e2b4f680fee68c.csv`\n",
    "\n",
    "Each trace file has a constant sized header of 24 lines (or 627 hexadecimal characters) containing all the acquisition information.\n",
    "The trace measurements values are listed right after the header.\n",
    "\n",
    "For instance, you could want to save disk space by converting your `.csv` traces files to the binary format and drop the header.\n",
    "As the metadata will be important to perform the side-channel analysis (plaintext, ciphertext), you must extract them from the filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import re # Regular expressions\n",
    "\n",
    "def csv2bin(file, offset, type, newfile):\n",
    "    \"\"\" Convert '.csv' file to '.bin' file format \n",
    "    \n",
    "    csv2bin converts a '.csv' input file containing one decimal value per line\n",
    "    into a '.bin' binary file.\n",
    "    \"\"\"\n",
    "    src_file = open(file, 'r')\n",
    "    src_file.read(offset)\n",
    "    lines = src_file.readlines()\n",
    "    pt_list = []\n",
    "    \n",
    "    for line in lines:\n",
    "        pt_list.append(struct.pack(type, int(line[:-1], base=10)))\n",
    "    src_file.close()\n",
    "    \n",
    "    dest_file = open(newfile, 'wb')\n",
    "    for point in pt_list:\n",
    "        dest_file.write(point)\n",
    "    dest_file.close()\n",
    "\n",
    "def csv2bin_parallel_call(files, offset, type, reg):\n",
    "    \"\"\" Parallel convert '.csv' file to '.bin' file format.\"\"\"\n",
    "    for file in files:\n",
    "        m = re.search(reg, file)\n",
    "        if m is None:\n",
    "            print(file)\n",
    "        else:\n",
    "            filename = file[:-3]+\"bin\"\n",
    "            Process(target=csv2bin, args=(file, offset,type,filename)).start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Executing the parallel conversion over all '.csv' files.\n",
    "regex = '([/a-zA-Z0-9_-]*)(n=[0-9]{1,5}_)([.=a-zA-Z0-9_-]*)'\n",
    "csv2bin_parallel_call(files, 627, 'h', regex)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.1.1.post20200322)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary files, we need to specify how to build trace set metadata to the traces reader, as a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'key': scared.traces.bin_extractor.PatternExtractor(r\"([A-Fa-f0-9]{32})\", num=0),\n",
    "    'plain': scared.traces.bin_extractor.PatternExtractor(r\"([A-Fa-f0-9]{32})\", num=1),\n",
    "    'cipher': scared.traces.bin_extractor.PatternExtractor(r\"([A-Fa-f0-9]{32})\", num=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the trace set:\n",
    "\n",
    "⚠ **Warning:** It can takes **20**GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No file found with pattern: '../../../../dpa_v2_files/*.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-308617f441cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'../../../../dpa_v2_files/*.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int16'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmetadatas_parsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/estraces/formats/bin_format.py\u001b[0m in \u001b[0;36mread_ths_from_bin_filenames_pattern\u001b[0;34m(filename_pattern, metadatas_parsers, dtype, headers, offset, padding_mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mfiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sorted_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     return read_ths_from_bin_filenames_list(\n\u001b[1;32m     70\u001b[0m         \u001b[0mfilenames_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/estraces/formats/bin_format.py\u001b[0m in \u001b[0;36mget_sorted_filenames\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No file found with pattern: '\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     files = sorted(\n\u001b[1;32m     27\u001b[0m         \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No file found with pattern: '../../../../dpa_v2_files/*.bin'"
     ]
    }
   ],
   "source": [
    "full_ths = scared.traces.read_ths_from_bin_filenames_pattern(\n",
    "    './DPA_contest2_public_base_diff_vcc_a128_2009_12_23/*.bin',\n",
    "    dtype='int16',\n",
    "    metadatas_parsers=metadata\n",
    ")\n",
    "print(full_ths)\n",
    "\n",
    "# Trace Header Set:\n",
    "# Name.............: BinFormat trace header set\n",
    "# Reader...........: Bin format reader with 640000 files, dtype int16\n",
    "# key..............: uint8\n",
    "# plain............: uint8\n",
    "# cipher...........: uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the traces corresponds to 32 subsets of 20,000 traces (One subset per key), we want to perfom the attack on only one subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = full_ths[0:20000]  # Pick the first subset of traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now study the traces. Here, the set contains 20 000 traces, with the same known key for all the traces, and plain and cipher for each trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to seting up the attack, let's try to focus on the right trace zone. Here, as we have the (plain, cipher) pairs together with the overall encryption measurement, we can try to target the first (yellow) and/or the last AES round (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(21, 5)\n",
    "data = ths.samples[0:3]\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('Power', fontsize=14)\n",
    "plt.plot(data.T)\n",
    "plt.axvspan(450, 650 , facecolor='y', alpha=0.3, label='First AES round')\n",
    "plt.axvspan(2340, 2395 , facecolor='r', alpha=0.3, label='Last AES round')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Attack the first round with CPA\n",
    "\n",
    "Here, we will proceed to an attack on the first AES round, with CPA method.\n",
    "First, we need to define the selection function to be used for intermediate values computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scared import aes\n",
    "\n",
    "# The attack selection function takes the targeted meta and guesses as arguments, and returns the intermediate values.\n",
    "# Here we target the first add round key output of the first aes round.\n",
    "@scared.attack_selection_function\n",
    "def first_add_key(plain, guesses):\n",
    "    res = np.empty((plain.shape[0], len(guesses), plain.shape[1]), dtype='uint8')\n",
    "    for i, guess in enumerate(guesses):\n",
    "        res[:, i, :] = np.bitwise_xor(plain, guess)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we can create the CAP attack object, passing it our selection function, a leakage model, and a discriminant function to compute key candidates scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_attack = scared.CPAAttack(\n",
    "    selection_function=first_add_key,\n",
    "    model=scared.HammingWeight(),\n",
    "    discriminant=scared.maxabs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the attack, we finally need to wrap our `TraceHeaderSet` with a trace container, specifiying the analysis frame to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round_container = scared.Container(ths[:10000], frame=slice(450, 650))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then proceed to the attack run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_attack.run(first_round_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the obtained best key candidate, and compare it to the expected first round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_first_round_key = np.argmax(cpa_attack.scores, axis=0)\n",
    "expected_first_round_key = aes.key_schedule(key=ths[0].key)[1]\n",
    "np.array_equal(expected_first_round_key, cpa_first_round_key)\n",
    "# False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No luck, this attack doesn't retrieve the good key. Let's now try to target the two last rounds of the AES.\n",
    "\n",
    "## Attack the last rounds with CPA\n",
    "\n",
    "We first have to define the corresponding selection function for the delta R between last two rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@scared.attack_selection_function\n",
    "def delta_last_two_rounds(cipher, guesses):\n",
    "    res = np.empty((cipher.shape[0], len(guesses), cipher.shape[1]), dtype='uint8')\n",
    "    for i, guess in enumerate(guesses):\n",
    "        s = aes.inv_sub_bytes(state=np.bitwise_xor(cipher, guess))\n",
    "        res[:, i, :] = np.bitwise_xor(aes.shift_rows(cipher), s)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a new container to target the last two rounds of the trace set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_rounds_container = scared.Container(ths[:15000], frame=slice(2340, 2395))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our new CPA analysis. Additionnaly, we use a 500 convergence step, so that we will be able to see how the result depends on the number of traces processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_attack = scared.CPAAttack(\n",
    "    selection_function=delta_last_two_rounds,\n",
    "    model=scared.HammingWeight(),\n",
    "    discriminant=scared.maxabs,\n",
    "    convergence_step=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the analysis on our container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_attack.run(last_rounds_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the best last round key candidate, and compare it to the expected key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_last_key = aes.key_schedule(key=ths[0].key)[-1]\n",
    "cpa_last_key = np.argmax(cpa_attack.scores, axis=0)\n",
    "np.array_equal(expected_last_key, cpa_last_key)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! The correct last key is retrieved. To finish, we have the ability to study the CPA traces and convergence scores evolution. Let's plot them for the byte 15 of the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('CPA trace - Byte 15', fontsize=20)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Correlation coefficient value', fontsize=12)\n",
    "plt.plot(cpa_attack.results[:, 15, :].T)\n",
    "\n",
    "# Plotting the convergence scores for byte 15\n",
    "plt.subplot(122)\n",
    "plt.title('Convergence score - Byte 15', fontsize=20)\n",
    "plt.xlabel('Number of traces', fontsize=14)\n",
    "plt.ylabel('CPA score', fontsize=14)\n",
    "plt.plot(cpa_attack.convergence_traces[:, 15,:].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best candidate value for this byte is clearly identified, both in correlation traces and convergence traces.\n",
    "Can we now make the same analysis with DPA method ?\n",
    "\n",
    "---\n",
    "\n",
    "## Attack the last round with DPA\n",
    "\n",
    "We will proceed to the same analysis than before on the last two rounds, but this time with DPA method.\n",
    "First, we will use a monobit leakage model on the bit 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_attack = scared.DPAAttack(\n",
    "    selection_function=delta_last_two_rounds,\n",
    "    model=scared.Monobit(7),\n",
    "    discriminant=scared.maxabs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_attack.run(last_rounds_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the obtained key, and compare it to the expected one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_key = np.argmax(dpa_attack.scores, axis=0)\n",
    "print(dpa_key)\n",
    "print(expected_last_key)\n",
    "# [148 159 123 136 216 184 196  54 116  90  36  95 239 133 192 225]\n",
    "# [ 83 159 177 136  64 126  43  63  45  90  36  95  80 254 190 225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, targeting the last bit does not allow us to recover the whole key bytes. Let's try attacking the other bits to retrieve the whole key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep record of the max DPA scores.\n",
    "max_scores = np.copy(dpa_attack.scores)\n",
    "\n",
    "for b in range(7):\n",
    "    print(\"Bit \", b)\n",
    "    dpa_analysis = scared.DPAAttack(\n",
    "        selection_function=delta_last_two_rounds,\n",
    "        model=scared.Monobit(b),\n",
    "        discriminant=scared.maxabs\n",
    "    )\n",
    "    dpa_analysis.run(last_rounds_container)\n",
    "    max_scores = np.maximum(max_scores, dpa_analysis.scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if we can retrieve all the key bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_key = np.argmax(max_scores, axis=0)\n",
    "np.array_equal(last_key, expected_last_key)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We have retrieve the whole key."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
